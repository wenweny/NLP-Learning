{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于CRF的中文命名实体识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 随机场是由若干个位置组成的整体，当按照某种分布给每一个位置随机赋予一个值之后，其全体就叫做随机场。\n",
    "- 马尔科夫随机场是随机场的特例，它假设随机场中某一个位置的赋值仅仅与和它相邻的位置的赋值有关，和与其不相邻的位置的赋值无关。\n",
    "- CRF 是马尔科夫随机场的特例，它假设马尔科夫随机场中只有 X 和 Y 两种变量，X 一般是给定的，而 Y 一般是在给定 X 的条件下我们的输出。这样马尔科夫随机场就特化成了条件随机场。\n",
    "- 对于 CRF，我们给出准确的数学语言描述：设 X 与 Y 是随机变量，P(Y|X) 是给定 X 时 Y 的条件概率分布，若随机变量 Y 构成的是一个马尔科夫随机场，则称条件概率分布 P(Y|X) 是条件随机场。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据格式要求形如：\n",
    "\n",
    "12 O\n",
    "末 O\n",
    "周 O\n",
    "商 B-industry\n",
    "品 I-industry\n",
    "房 I-industry\n",
    "成 O\n",
    "交 O\n",
    "面 O\n",
    "积 O\n",
    "有 O\n",
    "所 O\n",
    "放 O\n",
    "大 O\n",
    "。\n",
    "\n",
    "\n",
    "字与标签之间以空格隔开，每句话中间以换行分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.externals import joblib\n",
    "import yaml\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    data_read_all = list()\n",
    "    data_sent_with_label = list()\n",
    "    with open(data_path, mode='r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip() == \"\":\n",
    "                data_read_all.append(data_sent_with_label.copy())\n",
    "                data_sent_with_label.clear()\n",
    "            else:\n",
    "                data_sent_with_label.append(tuple(line.strip().split(\" \")))\n",
    "    return data_read_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word': word,\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        words = word1 + word\n",
    "        features.update({\n",
    "            '-1:word': word1,\n",
    "            '-1:words': words,\n",
    "            '-1:word.isdigit()': word1.isdigit(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i > 1:\n",
    "        word2 = sent[i-2][0]\n",
    "        word1 = sent[i-1][0]\n",
    "        words = word1 + word2 + word\n",
    "        features.update({\n",
    "            '-2:word': word2,\n",
    "            '-2:words': words,\n",
    "            '-3:word.isdigit()': word1.isdigit(),\n",
    "        })\n",
    "\n",
    "    if i > 2:\n",
    "        word3 = sent[i - 3][0]\n",
    "        word2 = sent[i - 2][0]\n",
    "        word1 = sent[i - 1][0]\n",
    "        words = word1 + word2 + word3 + word\n",
    "        features.update({\n",
    "            '-3:word': word3,\n",
    "            '-3:words': words,\n",
    "            '-3:word.isdigit()': word1.isdigit(),\n",
    "        })\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        words = word1 + word\n",
    "        features.update({\n",
    "            '+1:word': word1,\n",
    "            '+1:words': words,\n",
    "            '+1:word.isdigit()': word1.isdigit(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    if i < len(sent)-2:\n",
    "        word2 = sent[i + 2][0]\n",
    "        word1 = sent[i + 1][0]\n",
    "        words = word + word1 + word2\n",
    "        features.update({\n",
    "            '+2:word': word2,\n",
    "            '+2:words': words,\n",
    "            '+2:word.isdigit()': word2.isdigit(),\n",
    "        })\n",
    "\n",
    "    if i < len(sent)-3:\n",
    "        word3 = sent[i + 3][0]\n",
    "        word2 = sent[i + 2][0]\n",
    "        word1 = sent[i + 1][0]\n",
    "        words = word + word1 + word2 + word3\n",
    "        features.update({\n",
    "            '+3:word': word3,\n",
    "            '+3:words': words,\n",
    "            '+3:word.isdigit()': word3.isdigit(),\n",
    "        })\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [ele[-1] for ele in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./NER_config.yml') as f:\n",
    "        hp = yaml.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = load_data(hp['data_train'])\n",
    "test_corpus = load_data(hp['data_dev'])\n",
    "\n",
    "X_train = [sent2features(s) for s in train_corpus]\n",
    "y_train = [sent2labels(s) for s in train_corpus]\n",
    "\n",
    "X_dev = [sent2features(s) for s in test_corpus]\n",
    "y_dev = [sent2labels(s) for s in test_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 4232/4232 [00:06<00:00, 649.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 688227\n",
      "Seconds required: 1.886\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.250000\n",
      "c2: 0.018000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.40  loss=74015.64 active=686162 feature_norm=1.00\n",
      "Iter 2   time=0.21  loss=55168.33 active=680668 feature_norm=1.44\n",
      "Iter 3   time=0.23  loss=53448.33 active=257166 feature_norm=1.53\n",
      "Iter 4   time=0.22  loss=50159.52 active=225741 feature_norm=1.76\n",
      "Iter 5   time=0.22  loss=43384.43 active=157893 feature_norm=2.03\n",
      "Iter 6   time=0.58  loss=39856.83 active=133583 feature_norm=3.00\n",
      "Iter 7   time=0.22  loss=36560.75 active=159338 feature_norm=2.95\n",
      "Iter 8   time=0.22  loss=34255.21 active=158556 feature_norm=3.19\n",
      "Iter 9   time=0.59  loss=31861.58 active=157267 feature_norm=3.63\n",
      "Iter 10  time=0.23  loss=30317.03 active=160124 feature_norm=4.05\n",
      "Iter 11  time=0.43  loss=28764.86 active=158226 feature_norm=5.00\n",
      "Iter 12  time=0.23  loss=26532.82 active=168136 feature_norm=6.01\n",
      "Iter 13  time=0.22  loss=24909.86 active=163526 feature_norm=7.59\n",
      "Iter 14  time=0.22  loss=23314.70 active=172256 feature_norm=9.01\n",
      "Iter 15  time=0.22  loss=21115.31 active=166218 feature_norm=10.32\n",
      "Iter 16  time=0.22  loss=19093.25 active=173199 feature_norm=11.56\n",
      "Iter 17  time=0.23  loss=16978.16 active=166633 feature_norm=13.84\n",
      "Iter 18  time=0.40  loss=16774.56 active=138325 feature_norm=16.73\n",
      "Iter 19  time=0.22  loss=14618.36 active=139246 feature_norm=18.62\n",
      "Iter 20  time=0.23  loss=13731.22 active=138761 feature_norm=19.99\n",
      "Iter 21  time=0.23  loss=12333.20 active=137054 feature_norm=23.13\n",
      "Iter 22  time=0.22  loss=10974.17 active=132173 feature_norm=26.80\n",
      "Iter 23  time=0.22  loss=9935.57  active=133244 feature_norm=29.79\n",
      "Iter 24  time=0.22  loss=8931.23  active=130366 feature_norm=34.17\n",
      "Iter 25  time=0.22  loss=8045.60  active=125448 feature_norm=39.27\n",
      "Iter 26  time=0.22  loss=7400.13  active=118544 feature_norm=44.77\n",
      "Iter 27  time=0.23  loss=6927.61  active=116757 feature_norm=47.38\n",
      "Iter 28  time=0.22  loss=6450.38  active=110210 feature_norm=51.38\n",
      "Iter 29  time=0.22  loss=5839.06  active=104466 feature_norm=57.77\n",
      "Iter 30  time=0.23  loss=5526.79  active=100486 feature_norm=61.59\n",
      "Iter 31  time=0.23  loss=5242.12  active=98234 feature_norm=64.07\n",
      "Iter 32  time=0.22  loss=4944.04  active=89725 feature_norm=67.56\n",
      "Iter 33  time=0.23  loss=4706.05  active=82898 feature_norm=69.45\n",
      "Iter 34  time=0.23  loss=4532.29  active=79027 feature_norm=71.81\n",
      "Iter 35  time=0.22  loss=4387.04  active=75390 feature_norm=73.24\n",
      "Iter 36  time=0.22  loss=4264.08  active=72425 feature_norm=75.21\n",
      "Iter 37  time=0.22  loss=4156.18  active=69032 feature_norm=76.35\n",
      "Iter 38  time=0.22  loss=4062.23  active=65328 feature_norm=78.63\n",
      "Iter 39  time=0.22  loss=3985.77  active=64019 feature_norm=79.73\n",
      "Iter 40  time=0.23  loss=3915.45  active=58049 feature_norm=81.70\n",
      "Iter 41  time=0.22  loss=3859.09  active=54365 feature_norm=83.01\n",
      "Iter 42  time=0.22  loss=3816.06  active=52519 feature_norm=84.74\n",
      "Iter 43  time=0.22  loss=3775.47  active=49393 feature_norm=85.78\n",
      "Iter 44  time=0.22  loss=3744.40  active=47510 feature_norm=87.43\n",
      "Iter 45  time=0.22  loss=3713.02  active=45602 feature_norm=88.07\n",
      "Iter 46  time=0.22  loss=3686.12  active=44135 feature_norm=89.07\n",
      "Iter 47  time=0.22  loss=3657.62  active=42147 feature_norm=89.57\n",
      "Iter 48  time=0.22  loss=3633.62  active=41063 feature_norm=90.53\n",
      "Iter 49  time=0.25  loss=3611.64  active=39812 feature_norm=90.84\n",
      "Iter 50  time=0.22  loss=3589.64  active=38752 feature_norm=91.48\n",
      "Iter 51  time=0.22  loss=3565.95  active=37345 feature_norm=91.74\n",
      "Iter 52  time=0.22  loss=3548.47  active=36251 feature_norm=92.22\n",
      "Iter 53  time=0.22  loss=3532.62  active=35441 feature_norm=92.24\n",
      "Iter 54  time=0.22  loss=3517.82  active=34898 feature_norm=92.52\n",
      "Iter 55  time=0.22  loss=3500.31  active=33708 feature_norm=92.52\n",
      "Iter 56  time=0.22  loss=3487.00  active=33027 feature_norm=92.89\n",
      "Iter 57  time=0.22  loss=3474.81  active=32176 feature_norm=92.91\n",
      "Iter 58  time=0.23  loss=3464.27  active=31622 feature_norm=93.11\n",
      "Iter 59  time=0.23  loss=3451.73  active=30789 feature_norm=93.26\n",
      "Iter 60  time=0.22  loss=3443.23  active=30175 feature_norm=93.63\n",
      "Iter 61  time=0.22  loss=3434.35  active=29903 feature_norm=93.70\n",
      "Iter 62  time=0.22  loss=3427.26  active=29577 feature_norm=93.91\n",
      "Iter 63  time=0.22  loss=3418.41  active=28986 feature_norm=94.08\n",
      "Iter 64  time=0.24  loss=3412.83  active=28766 feature_norm=94.41\n",
      "Iter 65  time=0.23  loss=3405.94  active=28502 feature_norm=94.44\n",
      "Iter 66  time=0.22  loss=3400.39  active=28311 feature_norm=94.62\n",
      "Iter 67  time=0.22  loss=3392.91  active=27818 feature_norm=94.73\n",
      "Iter 68  time=0.22  loss=3389.25  active=27507 feature_norm=95.10\n",
      "Iter 69  time=0.22  loss=3381.80  active=27407 feature_norm=95.13\n",
      "Iter 70  time=0.22  loss=3377.58  active=27311 feature_norm=95.30\n",
      "Iter 71  time=0.22  loss=3371.63  active=26975 feature_norm=95.39\n",
      "Iter 72  time=0.22  loss=3367.99  active=26649 feature_norm=95.74\n",
      "Iter 73  time=0.22  loss=3361.77  active=26477 feature_norm=95.79\n",
      "Iter 74  time=0.22  loss=3358.58  active=26405 feature_norm=95.96\n",
      "Iter 75  time=0.22  loss=3354.52  active=26184 feature_norm=96.04\n",
      "Iter 76  time=0.22  loss=3350.65  active=25787 feature_norm=96.34\n",
      "Iter 77  time=0.22  loss=3346.68  active=25600 feature_norm=96.40\n",
      "Iter 78  time=0.22  loss=3343.49  active=25685 feature_norm=96.64\n",
      "Iter 79  time=0.22  loss=3340.64  active=25536 feature_norm=96.70\n",
      "Iter 80  time=0.22  loss=3337.67  active=25407 feature_norm=96.85\n",
      "Iter 81  time=0.22  loss=3334.19  active=25007 feature_norm=96.97\n",
      "Iter 82  time=0.22  loss=3331.71  active=25059 feature_norm=97.23\n",
      "Iter 83  time=0.22  loss=3328.77  active=24907 feature_norm=97.28\n",
      "Iter 84  time=0.22  loss=3326.89  active=24869 feature_norm=97.38\n",
      "Iter 85  time=0.22  loss=3323.75  active=24637 feature_norm=97.47\n",
      "Iter 86  time=0.22  loss=3321.59  active=24432 feature_norm=97.67\n",
      "Iter 87  time=0.22  loss=3318.75  active=24347 feature_norm=97.72\n",
      "Iter 88  time=0.22  loss=3316.95  active=24367 feature_norm=97.80\n",
      "Iter 89  time=0.22  loss=3314.18  active=24117 feature_norm=97.88\n",
      "Iter 90  time=0.22  loss=3312.65  active=23916 feature_norm=98.05\n",
      "Iter 91  time=0.22  loss=3309.83  active=23898 feature_norm=98.08\n",
      "Iter 92  time=0.22  loss=3308.21  active=23859 feature_norm=98.14\n",
      "Iter 93  time=0.22  loss=3305.54  active=23525 feature_norm=98.20\n",
      "Iter 94  time=0.22  loss=3304.35  active=23322 feature_norm=98.33\n",
      "Iter 95  time=0.22  loss=3301.98  active=23272 feature_norm=98.32\n",
      "Iter 96  time=0.22  loss=3300.65  active=23250 feature_norm=98.35\n",
      "Iter 97  time=0.22  loss=3297.71  active=22881 feature_norm=98.36\n",
      "Iter 98  time=0.23  loss=3296.28  active=22859 feature_norm=98.42\n",
      "Iter 99  time=0.22  loss=3294.39  active=22839 feature_norm=98.41\n",
      "Iter 100 time=0.22  loss=3292.67  active=22668 feature_norm=98.43\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 23.579\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 22668 (688227)\n",
      "Number of active attributes: 17518 (668393)\n",
      "Number of active labels: 3 (3)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.021\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.25, c2=0.018, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# **表示该位置接受任意多个关键字（keyword）参数，在函数**位置上转化为词典 [key:value, key:value ]\n",
    "crf_model = sklearn_crfsuite.CRF(**hp[\"CRF_hyper\"],verbose=True)\n",
    "crf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.验证模型效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-industry      0.875     0.759     0.813       572\n",
      "  I-industry      0.868     0.776     0.819      1352\n",
      "\n",
      "   micro avg      0.870     0.771     0.817      1924\n",
      "   macro avg      0.871     0.767     0.816      1924\n",
      "weighted avg      0.870     0.771     0.817      1924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels=list(crf_model.classes_)\n",
    "labels.remove(\"O\")\n",
    "y_pred = crf_model.predict(X_dev)\n",
    "metrics.flat_f1_score(y_dev, y_pred,\n",
    "                      average='weighted', labels=labels)\n",
    "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0]))\n",
    "print(metrics.flat_classification_report(\n",
    "    y_dev, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./small_corpus_crf_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(crf_model, \"./small_corpus_crf_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.使用模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('国', 'O'),\n",
       " ('际', 'O'),\n",
       " ('成', 'O'),\n",
       " ('品', 'O'),\n",
       " ('油', 'O'),\n",
       " ('需', 'O'),\n",
       " ('求', 'O'),\n",
       " ('大', 'O'),\n",
       " ('幅', 'O'),\n",
       " ('下', 'O'),\n",
       " ('滑', 'O'),\n",
       " ('，', 'O'),\n",
       " ('国', 'O'),\n",
       " ('际', 'O'),\n",
       " ('原', 'B-industry'),\n",
       " ('油', 'I-industry'),\n",
       " ('的', 'O'),\n",
       " ('最', 'O'),\n",
       " ('大', 'O'),\n",
       " ('需', 'O'),\n",
       " ('求', 'O'),\n",
       " ('来', 'O'),\n",
       " ('源', 'O'),\n",
       " ('于', 'O'),\n",
       " ('成', 'O'),\n",
       " ('品', 'O'),\n",
       " ('油', 'O'),\n",
       " ('。', 'O')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '国际成品油需求大幅下滑，国际原油的最大需求来源于成品油。'\n",
    "\n",
    "NER_tagger = joblib.load('./small_corpus_crf_model.pkl')\n",
    "list_result = []\n",
    "new_sents = re.split(u'(。|！|\\!|？|\\?)', text)\n",
    "sents_feature = [sent2features(sent) for sent in new_sents]\n",
    "y_pred = NER_tagger.predict(sents_feature)\n",
    "for sent, ner_tag in zip(new_sents, y_pred):\n",
    "    for word, tag in zip(sent, ner_tag):\n",
    "        list_result.append((word,tag))\n",
    "list_result        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可以在模型训练前使用RandomizedSearchCV或GridSearchCV寻找最优参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV：网格搜索和交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomizedSearchCV ：以随机在参数空间中采样的方式代替了GridSearchCV对于参数的网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 63.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "                                 all_possible_transitions=True, averaging=None,\n",
       "                                 c=None, c1=None, c2=None,\n",
       "                                 calibration_candidates=None,\n",
       "                                 calibration_eta=None,\n",
       "                                 calibration_max_trials=None,\n",
       "                                 calibration_rate=None,\n",
       "                                 calibration_samples=None, delta=None,\n",
       "                                 epsilon=None, error_sensitive=None,...\n",
       "                   iid='warn', n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fcf9f05f978>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fcf9f076358>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False,\n",
       "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['B-industry', 'I-industry']),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c1': 0.25321620648556353, 'c2': 0.018405602278209005}\n",
      "best CV score: 0.7675154799048618\n",
      "model size: 1.66M\n"
     ]
    }
   ],
   "source": [
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
