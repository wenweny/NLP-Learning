{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词袋模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用id映射的起因是因为 ，机器学习算法的输入都是数值，所以我们要把文本转化为数字送入网络。此时对应的数字仅代表分类，而不具有数值关系。\n",
    "同时，算法模型期望相同长度的语句，因此要将句子转化为一个稀疏向量。\n",
    "最开始的规则是：如果对应索引上的单词存在，则对应的索引位置的值为1。此方法的缺点是损失了句子中单词的顺序特征（也就是这个词出现了，则对应位置就为1，而与这个词出现在句子的哪个位置无关了）\n",
    "为解决上述问题，引入“词袋”嵌入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例子：使用“词袋”嵌入进行垃圾短信的预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import string\n",
    "from tensorflow.contrib import learn\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], float)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'D:\\datasets\\smsspamcollection\\SMSSpamCollection'\n",
    "\n",
    "df = pd.read_csv(file_path, delimiter='\\t', header=None)# 用\\t分割，没有文件头\n",
    "\n",
    "# 生成文本和标签\n",
    "target, texts = df[0], df[1]\n",
    "target = [1.0 if x=='spam' else 0.0 for x in target]\n",
    "target[:10],type(target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.对文本进行规则化处理，移除文本中大小写和数字的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat',\n",
       " 'ok lar joking wif u oni',\n",
       " 'free entry in  a wkly comp to win fa cup final tkts st may  text fa to  to receive entry questionstd txt ratetcs apply overs',\n",
       " 'u dun say so early hor u c already then say',\n",
       " 'nah i dont think he goes to usf he lives around here though']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [x.lower() for x in texts]\n",
    "# 去除标点\n",
    "texts = [''.join(c for c in x if c not in string.punctuation)for x in texts]\n",
    "# 去除数字\n",
    "texts = [''.join(c for c in x if c not in '1234567890')for x in texts]\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat',\n",
       " 'ok lar joking wif u oni',\n",
       " 'free entry in a wkly comp to win fa cup final tkts st may text fa to to receive entry questionstd txt ratetcs apply overs',\n",
       " 'u dun say so early hor u c already then say',\n",
       " 'nah i dont think he goes to usf he lives around here though']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去除多余空白？\n",
    "texts = [' '.join(x.split())for x in texts]\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.计算最长句子的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'histogram of words in texts')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 计算句子含有多少个单词，而不是句子字符串的长度\n",
    "text_lengths = [len(x.split()) for x in texts]\n",
    "text_lengths = [x for x in text_lengths if x <50]\n",
    "#bins是直方图柱子的个数，个数越多，划分的越细，柱子越多，那么数量每个柱子的数量可能就小了,normed=1是频率图，不加是频数图\n",
    "plt.hist(text_lengths,bins=25,normed=1,rwidth=0.7) \n",
    "plt.title('histogram of words in texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "['go', 'until', 'jurong', 'point', 'crazy', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'there', 'got', 'amore', 'wat']\n",
      "102\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for x in texts[:1]:\n",
    "    print(x)\n",
    "    print(x.split())\n",
    "    print(len(x))\n",
    "    print(len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用tensorflow分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-9f81cc81d9ee>:4: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From D:\\Programs\\Anaconda\\envs\\py36-tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\preprocessing\\text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From D:\\Programs\\Anaconda\\envs\\py36-tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\preprocessing\\text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2110"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_size = 25\n",
    "min_word_freq = 3\n",
    "\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(sentence_size,min_frequency= min_word_freq)\n",
    "vocab_processor.fit_transform(texts)\n",
    "embedding_size = len(vocab_processor.vocabulary_)\n",
    "embedding_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分割训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2252,  721, 2540, 3414, 1802, 4867, 1077, 4097, 5240, 1097])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices = np.random.choice(len(texts),round(len(texts)*0.8),replace=False)\n",
    "train_indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4, 4106,   11,   13, 2062,   15, 2064, 4110, 4115, 4117])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices = np.array(list(set(range(len(texts)))-set(train_indices)))\n",
    "test_indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 1114, 4458, 1114)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_train = [x for idx,x in enumerate(texts) if idx in train_indices]\n",
    "texts_test = [x for idx,x in enumerate(texts) if idx in test_indices]\n",
    "target_train = [x for idx,x in enumerate(target) if idx in train_indices]\n",
    "target_test = [x for idx,x in enumerate(target) if idx in test_indices]\n",
    "len(texts_train),len(texts_test),len(target_train),len(target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转化为词向量需要：\n",
    "1. 将句子单词转成索引\n",
    "2. 将索引转成one-hot向量，该向量为单位矩阵-->索引的时候可能有1、2、3，转换成one-hot就仅有0和1，索引数值所在位置为1，其余为0，所以每个单词是一行向量（embedding_size)，而每句话会是一个矩阵,有sentence_size行。\n",
    "3. 使用该矩阵为每个单词查找稀疏向量，并加入词稀疏向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，声明词嵌入矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ones:0' shape=(2110,) dtype=float32>,\n",
       " <tf.Tensor 'Diag:0' shape=(2110, 2110) dtype=float32>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_mat = tf.ones(shape=[embedding_size])\n",
    "identity_mat = tf.diag(ones_mat)\n",
    "ones_mat,identity_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(identity_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化占位符，并使用tf的嵌入查找函数来隐射句子中的单词为单位矩阵的one-hot向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Placeholder:0' shape=(25,) dtype=int32>,\n",
       " <tf.Tensor 'Placeholder_1:0' shape=(1, 1) dtype=float32>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_data 被用来查找单位矩阵的索引，tf要求其为整数类型\n",
    "x_data = tf.placeholder(shape = [sentence_size],dtype=tf.int32)\n",
    "y_target = tf.placeholder(shape=[1,1],dtype=tf.float32)\n",
    "x_data,y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup/Identity:0' shape=(25, 2110) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embed = tf.nn.embedding_lookup(identity_mat,x_data)\n",
    "x_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么要把前面的向量求和？？--> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum:0' shape=(2110,) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_col_sums = tf.reduce_sum(x_embed,0)\n",
    "x_col_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行逻辑回归，首先声明变量和模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable_2:0' shape=(2110, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(1, 1) dtype=float32_ref>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal(shape = [embedding_size,1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ExpandDims_1:0' shape=(1, 2110) dtype=float32>,\n",
       " <tf.Tensor 'Add_1:0' shape=(1, 1) dtype=float32>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_col_sums_2D = tf.expand_dims(x_col_sums,0)\n",
    "model_output = tf.add(tf.matmul(x_col_sums_2D,W),b)\n",
    "x_col_sums_2D,model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "声明训练模型的损失函数、预测函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_output,labels=y_target))\n",
    "prediction = tf.sigmoid(model_output)\n",
    "opt = tf.train.GradientDescentOptimizer(0.001)\n",
    "train_step = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化计算图中的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programs\\Anaconda\\envs\\py36-tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始迭代训练 没有写epoch为什么就训练4400代就自己停止了？？ -->不是4400代！是一代！然后4400+个单词，每个单词训练一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch # 0 : acc = 0.8530731269627636\n",
      "training epoch # 1 : acc = 0.8534096007178107\n",
      "training epoch # 2 : acc = 0.8538956183639899\n",
      "training epoch # 3 : acc = 0.8545872588604756\n",
      "training epoch # 4 : acc = 0.8551368326603859\n",
      "training epoch # 5 : acc = 0.8556901450575743\n",
      "training epoch # 6 : acc = 0.8561815035570083\n",
      "training epoch # 7 : acc = 0.8565500224315836\n",
      "training epoch # 8 : acc = 0.8569363441503415\n",
      "training epoch # 9 : acc = 0.857335127860027\n"
     ]
    }
   ],
   "source": [
    "loss_vec,train_acc_all,train_acc_avg = [],[],[]\n",
    "for i in range(10):\n",
    "    for idx,t in enumerate(vocab_processor.fit_transform(texts_train)):\n",
    "        sess.run(train_step,feed_dict = {x_data:t,y_target:y})\n",
    "        temp_loss = sess.run(loss,feed_dict={x_data:t,y_target:y})\n",
    "        loss_vec.append(temp_loss)\n",
    "        # 预测结果\n",
    "        [[temp_pred]]=sess.run(prediction,feed_dict={x_data:t,y_target:y})\n",
    "        #判断预测结果是否正确\n",
    "        train_acc_temp = target_train[idx]==np.round(temp_pred)\n",
    "        train_acc_all.append(train_acc_temp)\n",
    "    train_acc_avg = np.mean(train_acc_all)\n",
    "    print(\"training epoch # %s : acc = %s\"%(str(i),train_acc_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个非常简单、基础的词袋模型，不考虑单词的位置、权重等信息，单纯靠句子中出现过哪些单词（词袋中的单词）来进行映射，并进行one-hot稀疏编码。\n",
    "通过embedding_lookup对应一个句子（长度25）的编码矩阵（25*2110），通过行相加，得到句子的编码（2110）\n",
    "通过句子编码(2110,1)*W(1,2110)+b(1,1)= (1,1)训练W和b。\n",
    "没有经过网络层光通过embedding层竟然能达到85%的准确率。参考资料说是因为长度25的限定，限定的好？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-tensorflow",
   "language": "python",
   "name": "py36-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
